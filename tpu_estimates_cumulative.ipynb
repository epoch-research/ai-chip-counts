{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d054e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import squigglepy as sq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from squigglepy.numbers import K, M, B\n",
    "\n",
    "sq.set_seed(42)\n",
    "np.random.seed(42)\n",
    "np.seterr(invalid='raise')  # Warn on operations involving NaN\n",
    "N_SAMPLES = 5000\n",
    "\n",
    "from chip_estimates_utils import (\n",
    "    normalize_shares,\n",
    "    estimate_chip_sales,\n",
    "    estimate_cumulative_chip_sales,\n",
    "    aggregate_by_chip_type,\n",
    "    interpolate_samples_to_calendar_quarters,\n",
    "    compute_running_totals,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0dfdb0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# GOOGLE SHEETS CONFIGURATION\n",
    "# ==============================================\n",
    "\n",
    "SPREADSHEET_ID = \"1eGk2AAdewEO81vx-YBRTtdlhZvAMstY7vZuHrf3sgNI\"\n",
    "\n",
    "REVENUE_SHEET = \"TPU_Revenue\"\n",
    "PROD_MIX_SHEET = \"Production_Mix\"\n",
    "PRICES_SHEET = \"prices\"\n",
    "\n",
    "# Construct URLs for direct CSV export\n",
    "REVENUE_URL = f\"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={REVENUE_SHEET}\"\n",
    "PROD_MIX_URL = f\"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={PROD_MIX_SHEET}\"\n",
    "PRICES_URL = f\"https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/gviz/tq?tqx=out:csv&sheet={PRICES_SHEET}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a533438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 12 quarters of revenue data\n",
      "   quarter  start_date    end_date  revenue_p5  revenue_p95  \\\n",
      "0  Q1_FY23  10/31/2022   1/29/2023        0.42         0.53   \n",
      "1  Q2_FY23   1/30/2023   4/30/2023        0.53         0.66   \n",
      "2  Q3_FY23    5/1/2023   7/30/2023        0.53         0.66   \n",
      "3  Q4_FY23   7/31/2023  10/29/2023        0.79         0.99   \n",
      "4  Q1_FY24  10/30/2023    2/4/2024        1.30         1.45   \n",
      "\n",
      "   broadcom_margin_p5  broadcom_margin_p95  \n",
      "0                0.55                 0.70  \n",
      "1                0.55                 0.70  \n",
      "2                0.55                 0.70  \n",
      "3                0.55                 0.70  \n",
      "4                0.50                 0.65  \n",
      "\n",
      "   quarter version  share_p5  share_p95\n",
      "0  Q1_FY23      v4      0.60       0.80\n",
      "1  Q1_FY23     v4i      0.10       0.20\n",
      "2  Q1_FY23     v5e      0.10       0.20\n",
      "3  Q2_FY23      v4      0.60       0.90\n",
      "4  Q2_FY23     v5e      0.10       0.40\n",
      "5  Q3_FY23     v5e      0.65       0.95\n",
      "6  Q3_FY23      v4      0.05       0.35\n",
      "7  Q4_FY23     v5e      1.00       1.00\n",
      "8  Q1_FY24     v5e      0.85       0.95\n",
      "9  Q1_FY24     v5p      0.05       0.15\n",
      "\n",
      "  version  cost_p5  cost_p95\n",
      "0      v3      940      1400\n",
      "1     v4i      700      1100\n",
      "2      v4     1100      1500\n",
      "3     v5e      950      1400\n",
      "4     v5p     2300      2900\n",
      "5     v6e     1600      1900\n",
      "6      v7     4600      5500\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# LOAD DATA FROM GOOGLE SHEETS\n",
    "# ==============================================\n",
    "\n",
    "revenue_df = pd.read_csv(REVENUE_URL).dropna(axis=1, how=\"all\")\n",
    "prod_mix_df = pd.read_csv(PROD_MIX_URL).dropna(axis=1, how=\"all\")\n",
    "prices_df = pd.read_csv(PRICES_URL).dropna(axis=1, how=\"all\")\n",
    "\n",
    "QUARTERS = revenue_df['quarter'].tolist()\n",
    "TPU_VERSIONS = prod_mix_df['version'].dropna().unique().tolist()\n",
    "\n",
    "print(f\"Loaded {len(revenue_df)} quarters of revenue data\")\n",
    "print(revenue_df[['quarter', 'start_date', 'end_date', 'revenue_p5', 'revenue_p95', 'broadcom_margin_p5', 'broadcom_margin_p95']].head())\n",
    "print()\n",
    "print(prod_mix_df[['quarter', 'version', 'share_p5', 'share_p95']].head(10))\n",
    "print()\n",
    "print(prices_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7a0a9385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPU costs (90% CI):\n",
      "  v3: $940-$1,400\n",
      "  v4i: $700-$1,100\n",
      "  v4: $1,100-$1,500\n",
      "  v5e: $950-$1,400\n",
      "  v5p: $2,300-$2,900\n",
      "  v6e: $1,600-$1,900\n",
      "  v7: $4,600-$5,500\n",
      "Broadcom margins (first 6 quarters):\n",
      "  Q1_FY23: 55%-70%\n",
      "  Q2_FY23: 55%-70%\n",
      "  Q3_FY23: 55%-70%\n",
      "  Q4_FY23: 55%-70%\n",
      "  Q1_FY24: 50%-65%\n",
      "  Q2_FY24: 50%-65%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# CONVERT TO SQUIGGLEPY DISTRIBUTIONS\n",
    "# ==============================================\n",
    "\n",
    "TPU_REVENUE = {}\n",
    "for _, row in revenue_df.iterrows():\n",
    "    quarter = row['quarter']\n",
    "    TPU_REVENUE[quarter] = sq.norm(row['revenue_p5'], row['revenue_p95'])\n",
    "\n",
    "PROD_MIX = {}\n",
    "for quarter in prod_mix_df['quarter'].unique():\n",
    "    quarter_data = prod_mix_df[prod_mix_df['quarter'] == quarter]\n",
    "    PROD_MIX[quarter] = {}\n",
    "    for _, row in quarter_data.iterrows():\n",
    "        version = row['version']\n",
    "        PROD_MIX[quarter][version] = sq.norm(row['share_p5'], row['share_p95'], lclip=0, rclip=1)\n",
    "\n",
    "TPU_SPECS = {\n",
    "    'v3':  {'tops': 123,  'full_name': 'TPU v3'},\n",
    "    'v4i': {'tops': 138,  'full_name': 'TPU v4i'},\n",
    "    'v4':  {'tops': 275,  'full_name': 'TPU v4'},\n",
    "    'v5e': {'tops': 393,  'full_name': 'TPU v5e'},\n",
    "    'v5p': {'tops': 918,  'full_name': 'TPU v5p'},\n",
    "    'v6e': {'tops': 1836, 'full_name': 'TPU v6e'},\n",
    "    'v7':  {'tops': 4614, 'full_name': 'TPU v7'},\n",
    "}\n",
    "\n",
    "# TPU manufacturing costs from prices sheet\n",
    "TPU_COST = {row['version']: sq.to(row['cost_p5'], row['cost_p95']) for _, row in prices_df.iterrows()}\n",
    "\n",
    "# Broadcom margins by quarter from revenue sheet\n",
    "MARGIN_BY_QUARTER = {row['quarter']: sq.to(row['broadcom_margin_p5'], row['broadcom_margin_p95']) for _, row in revenue_df.iterrows()}\n",
    "\n",
    "print(\"TPU costs (90% CI):\")\n",
    "for v, cost in TPU_COST.items():\n",
    "    print(f\"  {v}: ${cost.x:,.0f}-${cost.y:,.0f}\")\n",
    "\n",
    "print(\"Broadcom margins (first 6 quarters):\")\n",
    "for q in list(MARGIN_BY_QUARTER.keys())[:6]:\n",
    "    m = MARGIN_BY_QUARTER[q]\n",
    "    print(f\"  {q}: {m.x:.0%}-{m.y:.0%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c5e46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FY24+ deflation factor: 0.8763\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# SAMPLING FUNCTIONS\n",
    "# ==============================================\n",
    "\n",
    "# Base quarter for correlated price sampling (prices sampled once per chip, using this quarter's margin)\n",
    "BASE_QUARTER = QUARTERS[0]\n",
    "\n",
    "\n",
    "def sample_revenue(quarter):\n",
    "    return (TPU_REVENUE[quarter] @ 1) * B\n",
    "\n",
    "\n",
    "def sample_shares(quarter):\n",
    "    mix = PROD_MIX[quarter]\n",
    "    raw_shares = {version: dist @ 1 for version, dist in mix.items()}\n",
    "    return normalize_shares(raw_shares)\n",
    "\n",
    "\n",
    "def sample_base_price(version):\n",
    "    \"\"\"Sample base price = cost / (1 - margin) using base quarter margin.\"\"\"\n",
    "    return (TPU_COST[version] / (1 - MARGIN_BY_QUARTER[BASE_QUARTER])) @ 1\n",
    "\n",
    "\n",
    "# Uncorrelated price sampler (for comparison)\n",
    "def sample_price(quarter, version):\n",
    "    \"\"\"Sample price = cost / (1 - margin)\"\"\"\n",
    "    return (TPU_COST[version] / (1 - MARGIN_BY_QUARTER[quarter])) @ 1\n",
    "\n",
    "\n",
    "# Margin deflation factor for correlated model\n",
    "# \n",
    "# We want to adjust prices based on each quarter's margin while keeping price\n",
    "# uncertainty correlated across time. The base price is sampled once using\n",
    "# BASE_QUARTER's margin, then scaled by this deflation factor for other quarters.\n",
    "#\n",
    "# We compute this empirically rather than using closed-form because:\n",
    "# 1. price = cost / (1 - margin), and 1/(1-x) is convex (Jensen's inequality)\n",
    "# 2. We want E[1/(1-margin_q)] / E[1/(1-margin_base)], not the ratio of medians\n",
    "# 3. For lognormal margins, the mean of the transform ≠ transform of the mean\n",
    "#\n",
    "# Since margin only changes once (FY23: 55-70% → FY24+: 50-65%), we compute\n",
    "# the deflation factor once and apply it based on fiscal year.\n",
    "\n",
    "def _compute_expected_price_multiplier(margin_dist, n=10000):\n",
    "    \"\"\"Compute E[1/(1-margin)] by sampling.\"\"\"\n",
    "    samples = margin_dist @ n\n",
    "    return np.mean(1 / (1 - samples))\n",
    "\n",
    "# Compute deflation factor for FY24+ relative to FY23\n",
    "FY23_MARGIN = sq.to(0.55, 0.70)\n",
    "FY24_MARGIN = sq.to(0.50, 0.65)\n",
    "FY24_DEFLATION = _compute_expected_price_multiplier(FY24_MARGIN) / _compute_expected_price_multiplier(FY23_MARGIN)\n",
    "\n",
    "def get_margin_deflation_factor(quarter, version):\n",
    "    \"\"\"Return price adjustment factor: 1.0 for FY23, ~0.88 for FY24+.\"\"\"\n",
    "    if 'FY23' in quarter:\n",
    "        return 1.0\n",
    "    return FY24_DEFLATION\n",
    "\n",
    "print(f\"FY24+ deflation factor: {FY24_DEFLATION:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cba8d",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# RUN CORRELATED SIMULATION\n# ==============================================\n\nquarterly_samples = estimate_cumulative_chip_sales(\n    quarters=QUARTERS,\n    chip_types=TPU_VERSIONS,\n    sample_revenue=sample_revenue,\n    sample_shares=sample_shares,\n    sample_base_price=sample_base_price,\n    get_deflation_factor=get_margin_deflation_factor,\n    sample_revenue_uncertainty=None,\n    n_samples=N_SAMPLES,\n)\n\ncumulative_samples = aggregate_by_chip_type(quarterly_samples)\n\nprint(\"Simulation complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaca4470",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# CUMULATIVE SUMMARY\n# ==============================================\n\ndef print_cumulative_summary(cumulative_samples, versions, title=\"Cumulative Production\"):\n    print(f\"{title}\")\n    print(f\"{'Version':<8} {'p5':>12} {'p50':>12} {'p95':>12}\")\n    print(\"-\" * 51)\n\n    grand_total = None\n    for v in versions:\n        arr = cumulative_samples[v]\n        if arr.sum() > 0:\n            if grand_total is None:\n                grand_total = np.zeros_like(arr)\n            grand_total += arr\n            print(f\"{v:<8} {int(np.percentile(arr, 5)):>12,} {int(np.percentile(arr, 50)):>12,} {int(np.percentile(arr, 95)):>12,}\")\n\n    if grand_total is not None:\n        print(\"-\" * 51)\n        print(f\"{'TOTAL':<8} {int(np.percentile(grand_total, 5)):>12,} {int(np.percentile(grand_total, 50)):>12,} {int(np.percentile(grand_total, 95)):>12,}\")\n\nprint_cumulative_summary(cumulative_samples, TPU_VERSIONS, \"Cumulative TPU Production (Correlated Model)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61e10c",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# CUMULATIVE RUNNING TOTALS BY FISCAL QUARTER\n# ==============================================\n\nrunning_totals_samples = compute_running_totals(quarterly_samples)\n\nprint(\"Cumulative Running Totals by Fiscal Quarter\")\nprint(f\"{'Quarter':<10} {'Version':<8} {'p5':>12} {'p50':>12} {'p95':>12}\")\nprint(\"=\" * 60)\n\nfor quarter in QUARTERS:\n    quarter_has_data = False\n    for v in TPU_VERSIONS:\n        arr = running_totals_samples[quarter][v]\n        if arr.sum() > 0:\n            quarter_has_data = True\n            print(f\"{quarter:<10} {v:<8} {int(np.percentile(arr, 5)):>12,} {int(np.percentile(arr, 50)):>12,} {int(np.percentile(arr, 95)):>12,}\")\n\n    if quarter_has_data:\n        total = sum(running_totals_samples[quarter][v] for v in TPU_VERSIONS)\n        print(f\"{quarter:<10} {'TOTAL':<8} {int(np.percentile(total, 5)):>12,} {int(np.percentile(total, 50)):>12,} {int(np.percentile(total, 95)):>12,}\")\n        print(\"-\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdfe504",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# CALENDAR QUARTER INTERPOLATION (SAMPLE-BASED)\n# ==============================================\n\nquarter_dates = {q: (revenue_df.loc[revenue_df['quarter'] == q, 'start_date'].iloc[0],\n                     revenue_df.loc[revenue_df['quarter'] == q, 'end_date'].iloc[0])\n                 for q in QUARTERS}\n\ncalendar_quarterly_samples = interpolate_samples_to_calendar_quarters(quarterly_samples, quarter_dates)\ncalendar_running_totals_samples = compute_running_totals(calendar_quarterly_samples)\n\nprint(\"Cumulative Running Totals by Calendar Quarter\")\nprint(f\"{'Quarter':<10} {'Version':<8} {'p5':>12} {'p50':>12} {'p95':>12}\")\nprint(\"=\" * 60)\n\nfor cq in calendar_running_totals_samples:\n    quarter_has_data = False\n    for v in TPU_VERSIONS:\n        arr = calendar_running_totals_samples[cq][v]\n        if arr.sum() > 0:\n            quarter_has_data = True\n            print(f\"{cq:<10} {v:<8} {int(np.percentile(arr, 5)):>12,} {int(np.percentile(arr, 50)):>12,} {int(np.percentile(arr, 95)):>12,}\")\n\n    if quarter_has_data:\n        total = sum(calendar_running_totals_samples[cq][v] for v in TPU_VERSIONS)\n        print(f\"{cq:<10} {'TOTAL':<8} {int(np.percentile(total, 5)):>12,} {int(np.percentile(total, 50)):>12,} {int(np.percentile(total, 95)):>12,}\")\n        print(\"-\" * 60)"
  },
  {
   "cell_type": "code",
   "id": "n8lnf3snl67",
   "source": "# ==============================================\n# CSV EXPORTS: CUMULATIVE RUNNING TOTALS BY CHIP TYPE\n# ==============================================\n# Export calendar quarter running totals broken down by TPU version\n\ndef get_calendar_quarter_dates(cal_q):\n    \"\"\"Return (start_date, end_date) strings for a calendar quarter like 'Q1 2024'.\"\"\"\n    parts = cal_q.split()\n    q_num = int(parts[0][1])\n    year = int(parts[1])\n    if q_num == 1:\n        return f\"1/1/{year}\", f\"3/31/{year}\"\n    elif q_num == 2:\n        return f\"4/1/{year}\", f\"6/30/{year}\"\n    elif q_num == 3:\n        return f\"7/1/{year}\", f\"9/30/{year}\"\n    else:\n        return f\"10/1/{year}\", f\"12/31/{year}\"\n\nrows = []\nfor cq in calendar_running_totals_samples:\n    start_date, end_date = get_calendar_quarter_dates(cq)\n    for version in TPU_VERSIONS:\n        arr = calendar_running_totals_samples[cq][version]\n        if arr.sum() > 0:\n            rows.append({\n                'Name': f\"Google {version} cumulative through {cq}\",\n                'Start date': start_date,\n                'End date': end_date,\n                'Chip type': version,\n                'Number of units (5th percentile)': int(np.percentile(arr, 5)),\n                'Number of units (median)': int(np.percentile(arr, 50)),\n                'Number of units (95th percentile)': int(np.percentile(arr, 95)),\n            })\n\nby_chip_df = pd.DataFrame(rows)\nby_chip_df.to_csv('tpu_cumulative_by_chip.csv', index=False)\nprint(f\"Exported {len(by_chip_df)} rows to tpu_cumulative_by_chip.csv\")\nprint(by_chip_df.head(10))",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ss55i8y2zua",
   "source": "# ==============================================\n# CSV EXPORTS: FULL-TPU AGGREGATE STATS\n# ==============================================\n# Export calendar quarter running totals with aggregate metrics across all TPU versions\n# Metrics: total units, H100e compute\n\nH100_TOPS = 1979  # Reference for H100-equivalent calculation\n\nrows = []\nfor cq in calendar_running_totals_samples:\n    start_date, end_date = get_calendar_quarter_dates(cq)\n    \n    # Compute aggregate metrics across all TPU versions\n    n_samples = N_SAMPLES\n    units_total = np.zeros(n_samples)\n    h100e_total = np.zeros(n_samples)\n    \n    for version in TPU_VERSIONS:\n        arr = calendar_running_totals_samples[cq][version]\n        units_total += arr\n        if version in TPU_SPECS:\n            tops = TPU_SPECS[version]['tops']\n            h100e_total += arr * (tops / H100_TOPS)\n    \n    rows.append({\n        'Name': f\"Google TPU cumulative through {cq}\",\n        'Designer': 'Google',\n        'Start date': start_date,\n        'End date': end_date,\n        'Number of units (5th percentile)': int(np.percentile(units_total, 5)),\n        'Number of units (median)': int(np.percentile(units_total, 50)),\n        'Number of units (95th percentile)': int(np.percentile(units_total, 95)),\n        'Compute estimate in H100e (5th percentile)': int(np.percentile(h100e_total, 5)),\n        'Compute estimate in H100e (median)': int(np.percentile(h100e_total, 50)),\n        'Compute estimate in H100e (95th percentile)': int(np.percentile(h100e_total, 95)),\n    })\n\ntotals_df = pd.DataFrame(rows)\ntotals_df.to_csv('tpu_cumulative_totals.csv', index=False)\nprint(f\"Exported {len(totals_df)} rows to tpu_cumulative_totals.csv\")\nprint(totals_df)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538183d",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# CHRONOLOGICAL VIEW: FISCAL + CALENDAR INTERLEAVED\n# ==============================================\n\nfrom datetime import datetime\n\nselected_fiscal = QUARTERS[:5]\nselected_calendar = list(calendar_running_totals_samples.keys())[:4]\n\ntimeline = []\n\nfor q in selected_fiscal:\n    end_date = pd.to_datetime(revenue_df.loc[revenue_df['quarter'] == q, 'end_date'].iloc[0])\n    timeline.append({\n        'end_date': end_date,\n        'label': q,\n        'data': running_totals_samples[q],\n        'type': 'FISCAL',\n    })\n\nfor cq in selected_calendar:\n    parts = cq.split()\n    q_num, year = int(parts[0][1]), int(parts[1])\n    end_dates = {1: (3, 31), 2: (6, 30), 3: (9, 30), 4: (12, 31)}\n    end_date = datetime(year, *end_dates[q_num])\n    timeline.append({\n        'end_date': end_date,\n        'label': cq,\n        'data': calendar_running_totals_samples[cq],\n        'type': 'CALENDAR',\n    })\n\n# Sort chronologically\ntimeline.sort(key=lambda x: x['end_date'])\n\nprint(\"Chronological Comparison: Fiscal vs Calendar Quarter Running Totals\")\nprint(\"=\" * 80)\n\nfor entry in timeline:\n    print(f\"\\n{entry['type']}: {entry['label']} (ends {entry['end_date'].strftime('%Y-%m-%d')})\")\n    print(f\"  {'Version':<8} {'p5':>12} {'p50':>12} {'p95':>12}\")\n    print(f\"  {'-'*50}\")\n\n    total = np.zeros(N_SAMPLES)\n    for v in TPU_VERSIONS:\n        arr = entry['data'][v]\n        if arr.sum() > 0:\n            total += arr\n            print(f\"  {v:<8} {int(np.percentile(arr, 5)):>12,} {int(np.percentile(arr, 50)):>12,} {int(np.percentile(arr, 95)):>12,}\")\n\n    print(f\"  {'-'*50}\")\n    print(f\"  {'TOTAL':<8} {int(np.percentile(total, 5)):>12,} {int(np.percentile(total, 50)):>12,} {int(np.percentile(total, 95)):>12,}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80f773",
   "metadata": {},
   "outputs": [],
   "source": "# ==============================================\n# UNCORRELATED MODEL COMPARISON\n# ==============================================\n\nuncorrelated_samples = estimate_chip_sales(\n    quarters=QUARTERS,\n    versions=TPU_VERSIONS,\n    sample_revenue=sample_revenue,\n    sample_shares=sample_shares,\n    sample_price=sample_price,\n    n_samples=1000,  # smaller for speed\n)\n\ncumulative_uncorrelated_samples = aggregate_by_chip_type(uncorrelated_samples)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62894e4",
   "metadata": {},
   "outputs": [],
   "source": "print_cumulative_summary(cumulative_uncorrelated_samples, TPU_VERSIONS, \"Cumulative TPU Production (Uncorrelated Model)\")\nprint(\" \")\nprint_cumulative_summary(cumulative_samples, TPU_VERSIONS, \"Cumulative TPU Production (Correlated Model)\")"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Plotly)",
   "language": "python",
   "name": "plotly_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}