{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# NVIDIA Chip Estimates (v2 - Functional Sampling)\n",
    "\n",
    "This notebook uses a functional sampling architecture where `nvidia_sample()` returns a single sample of chip counts for all quarters and chips, with correlated parameters:\n",
    "- **Hardware share**: Sampled once per `nvidia_sample()` call (correlated across quarters)\n",
    "- **Base prices**: Sampled once per chip, with deflation applied deterministically\n",
    "\n",
    "This gives wider, more realistic confidence intervals for cumulative totals compared to independent sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import squigglepy as sq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from squigglepy.numbers import K, M, B\n",
    "\n",
    "sq.set_seed(42)\n",
    "np.random.seed(42)\n",
    "N_SAMPLES = 5000\n",
    "H100_TOPS = 1979"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA chip specs: 8-bit TFLOP/s\n",
    "CHIP_SPECS = {\n",
    "    'A100':      {'tops': 624},\n",
    "    'A800':      {'tops': 624},\n",
    "    'H100/H200': {'tops': 1979},\n",
    "    'H800':      {'tops': 1979},\n",
    "    'H20':       {'tops': 296},\n",
    "    'B200':      {'tops': 5000},\n",
    "    'B300':      {'tops': 5000},\n",
    "}\n",
    "CHIP_TYPES = list(CHIP_SPECS.keys())\n",
    "\n",
    "# Colors for visualization\n",
    "CHIP_COLORS = {\n",
    "    'A100': 'lightcoral',\n",
    "    'A800': 'sienna',\n",
    "    'H100/H200': 'steelblue',\n",
    "    'H800': 'firebrick',\n",
    "    'H20': 'orange',\n",
    "    'B200': 'mediumseagreen',\n",
    "    'B300': 'seagreen',\n",
    "}\n",
    "\n",
    "# Hardware share of compute revenue (vs cloud/software)\n",
    "HARDWARE_SHARE = sq.to(0.96, 0.99, credibility=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load revenue and price data from Google Sheets\n",
    "revenue_df = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/1Yhu87Rw--9tviAuBwg_luL3OFAFkdHdVfli6tN215Xk/export?format=csv&gid=0\"\n",
    ").set_index('Quarter')\n",
    "\n",
    "prices_df = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/1Yhu87Rw--9tviAuBwg_luL3OFAFkdHdVfli6tN215Xk/export?format=csv&gid=1819303346\"\n",
    ").set_index('Year')\n",
    "\n",
    "QUARTERS = revenue_df.index.tolist()\n",
    "\n",
    "revenue_df[['Compute revenue'] + [f'{chip} share' for chip in CHIP_TYPES]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "price_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Base price and deflation setup\n",
    "# ======================================================================\n",
    "\n",
    "# Map chip types to their column names in the prices CSV\n",
    "PRICE_COLUMN_MAP = {'H100/H200': 'H100'}\n",
    "\n",
    "# Fallback prices if not found in CSV\n",
    "FALLBACK_PRICES = {\n",
    "    'A100': (10*K, 15*K), 'A800': (10*K, 15*K), 'H100/H200': (20*K, 30*K),\n",
    "    'H800': (20*K, 30*K), 'H20': (10*K, 15*K), 'B200': (33*K, 42*K), 'B300': (33*K, 42*K)\n",
    "}\n",
    "\n",
    "\n",
    "def get_price_dist_for_year(chip, year):\n",
    "    \"\"\"Get price distribution for a chip in a given year.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col, high_col = f'{csv_chip_name} low', f'{csv_chip_name} high'\n",
    "\n",
    "    if low_col in prices_df.columns and high_col in prices_df.columns:\n",
    "        if year in prices_df.index:\n",
    "            low = prices_df.loc[year, low_col]\n",
    "            high = prices_df.loc[year, high_col]\n",
    "            if pd.notna(low) and pd.notna(high):\n",
    "                return sq.to(low, high, credibility=80)\n",
    "    return sq.to(*FALLBACK_PRICES.get(chip, (20*K, 30*K)), credibility=80)\n",
    "\n",
    "\n",
    "def find_first_year_with_price(chip):\n",
    "    \"\"\"Find the first year with price data for a chip.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col = f'{csv_chip_name} low'\n",
    "    if low_col in prices_df.columns:\n",
    "        for year in sorted(prices_df.index):\n",
    "            if pd.notna(prices_df.loc[year, low_col]):\n",
    "                return year\n",
    "    return min(prices_df.index)\n",
    "\n",
    "\n",
    "def get_price_year_for_quarter(quarter):\n",
    "    \"\"\"Get the calendar year to use for pricing a quarter.\"\"\"\n",
    "    start_date = revenue_df.loc[quarter, 'Start Date']\n",
    "    return pd.to_datetime(start_date).year\n",
    "\n",
    "\n",
    "def get_price_bounds(chip, year):\n",
    "    \"\"\"Get (low, high) price bounds for a chip in a given year, or None if unavailable.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col, high_col = f'{csv_chip_name} low', f'{csv_chip_name} high'\n",
    "    if low_col in prices_df.columns and high_col in prices_df.columns:\n",
    "        if year in prices_df.index:\n",
    "            low = prices_df.loc[year, low_col]\n",
    "            high = prices_df.loc[year, high_col]\n",
    "            if pd.notna(low) and pd.notna(high):\n",
    "                return (low, high)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_deflation_factor(quarter, chip):\n",
    "    \"\"\"Get deflation factor for a chip in a quarter (ratio of current to base price).\"\"\"\n",
    "    price_year = get_price_year_for_quarter(quarter)\n",
    "    base_year = BASE_YEAR[chip]\n",
    "    if price_year <= base_year:\n",
    "        return 1.0\n",
    "\n",
    "    base_bounds = get_price_bounds(chip, base_year)\n",
    "    current_bounds = get_price_bounds(chip, price_year)\n",
    "\n",
    "    if base_bounds and current_bounds:\n",
    "        # Ratio of geometric means\n",
    "        base_geomean = np.sqrt(base_bounds[0] * base_bounds[1])\n",
    "        current_geomean = np.sqrt(current_bounds[0] * current_bounds[1])\n",
    "        return current_geomean / base_geomean\n",
    "    return 1.0\n",
    "\n",
    "\n",
    "# Build base prices dict (first year available for each chip)\n",
    "BASE_YEAR = {chip: find_first_year_with_price(chip) for chip in CHIP_TYPES}\n",
    "BASE_PRICES = {chip: get_price_dist_for_year(chip, BASE_YEAR[chip]) for chip in CHIP_TYPES}\n",
    "\n",
    "print(\"Base years and price distributions:\")\n",
    "for chip in CHIP_TYPES:\n",
    "    bounds = get_price_bounds(chip, BASE_YEAR[chip])\n",
    "    if bounds:\n",
    "        print(f\"  {chip}: {BASE_YEAR[chip]} -> ${bounds[0]:,.0f} - ${bounds[1]:,.0f}\")\n",
    "    else:\n",
    "        fb = FALLBACK_PRICES.get(chip, (20*K, 30*K))\n",
    "        print(f\"  {chip}: {BASE_YEAR[chip]} -> ${fb[0]:,.0f} - ${fb[1]:,.0f} (fallback)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nvidia_sample",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Core sampling function\n",
    "# ======================================================================\n",
    "\n",
    "def nvidia_sample():\n",
    "    \"\"\"\n",
    "    Sample chip counts for all quarters and chips in a single call.\n",
    "\n",
    "    Correlates parameters within each sample:\n",
    "    - hardware_share: sampled once, applies to all quarters\n",
    "    - base_prices: sampled once per chip, deflation applied deterministically\n",
    "\n",
    "    Returns:\n",
    "        dict: {quarter: {chip: chip_count}} for a single sample\n",
    "    \"\"\"\n",
    "    # Sample correlated parameters ONCE for this sample\n",
    "    hardware_share = HARDWARE_SHARE @ 1\n",
    "    base_prices = {chip: BASE_PRICES[chip] @ 1 for chip in CHIP_TYPES}\n",
    "\n",
    "    result = {}\n",
    "    for quarter in QUARTERS:\n",
    "        result[quarter] = {}\n",
    "        base_revenue = revenue_df.loc[quarter, 'Compute revenue'] * B * hardware_share\n",
    "\n",
    "        for chip in CHIP_TYPES:\n",
    "            share = revenue_df.loc[quarter, f'{chip} share']\n",
    "            if pd.notna(share) and share > 0:\n",
    "                # Apply deflation factor to base price\n",
    "                price = base_prices[chip] * get_deflation_factor(quarter, chip)\n",
    "                result[quarter][chip] = (base_revenue * share) / price\n",
    "            else:\n",
    "                result[quarter][chip] = 0.0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregation_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Helper functions for aggregation\n",
    "# ======================================================================\n",
    "\n",
    "def cumulative_by_chip(sample):\n",
    "    \"\"\"Sum a single sample across all quarters, by chip.\"\"\"\n",
    "    totals = {chip: 0.0 for chip in CHIP_TYPES}\n",
    "    for quarter in sample:\n",
    "        for chip in CHIP_TYPES:\n",
    "            totals[chip] += sample[quarter][chip]\n",
    "    return totals\n",
    "\n",
    "\n",
    "def total_chips(sample):\n",
    "    \"\"\"Sum a single sample across all quarters and all chips.\"\"\"\n",
    "    return sum(cumulative_by_chip(sample).values())\n",
    "\n",
    "\n",
    "def quarterly_total(sample):\n",
    "    \"\"\"Sum a single sample across all chips, by quarter.\"\"\"\n",
    "    return {q: sum(sample[q].values()) for q in sample}\n",
    "\n",
    "\n",
    "def cumulative_total_by_quarter(sample):\n",
    "    \"\"\"Running total by quarter (cumulative sum of all chips over time).\"\"\"\n",
    "    running = 0\n",
    "    result = {}\n",
    "    for q in QUARTERS:\n",
    "        running += sum(sample[q].values())\n",
    "        result[q] = running\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interval_helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Helper functions for intervals\n",
    "# ======================================================================\n",
    "\n",
    "def get_quarterly_intervals(samples, percentiles=[5, 50, 95]):\n",
    "    \"\"\"\n",
    "    Extract per-quarter, per-chip intervals from list of samples.\n",
    "\n",
    "    Args:\n",
    "        samples: list of {quarter: {chip: count}} dicts\n",
    "\n",
    "    Returns:\n",
    "        dict: {quarter: {chip: {'p5': x, 'p50': y, 'p95': z}}}\n",
    "    \"\"\"\n",
    "    # Reorganize: {quarter: {chip: [values]}}\n",
    "    by_qc = {q: {c: [] for c in CHIP_TYPES} for q in QUARTERS}\n",
    "    for s in samples:\n",
    "        for q in QUARTERS:\n",
    "            for c in CHIP_TYPES:\n",
    "                by_qc[q][c].append(s[q][c])\n",
    "\n",
    "    # Compute percentiles\n",
    "    result = {}\n",
    "    for q in QUARTERS:\n",
    "        result[q] = {}\n",
    "        for c in CHIP_TYPES:\n",
    "            arr = np.array(by_qc[q][c])\n",
    "            result[q][c] = {f'p{p}': np.percentile(arr, p) for p in percentiles}\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_chip_intervals(samples, percentiles=[5, 50, 95]):\n",
    "    \"\"\"\n",
    "    Extract per-chip intervals from list of cumulative samples.\n",
    "\n",
    "    Args:\n",
    "        samples: list of {chip: count} dicts\n",
    "\n",
    "    Returns:\n",
    "        dict: {chip: {'p5': x, 'p50': y, 'p95': z}}\n",
    "    \"\"\"\n",
    "    by_chip = {c: [] for c in CHIP_TYPES}\n",
    "    for s in samples:\n",
    "        for c in CHIP_TYPES:\n",
    "            by_chip[c].append(s[c])\n",
    "\n",
    "    result = {}\n",
    "    for c in CHIP_TYPES:\n",
    "        arr = np.array(by_chip[c])\n",
    "        result[c] = {f'p{p}': np.percentile(arr, p) for p in percentiles}\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_scalar_intervals(samples, percentiles=[5, 50, 95]):\n",
    "    \"\"\"\n",
    "    Extract intervals from list of scalar samples.\n",
    "\n",
    "    Args:\n",
    "        samples: list of scalar values\n",
    "\n",
    "    Returns:\n",
    "        dict: {'p5': x, 'p50': y, 'p95': z}\n",
    "    \"\"\"\n",
    "    arr = np.array(samples)\n",
    "    return {f'p{p}': np.percentile(arr, p) for p in percentiles}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run_sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Main execution: collect samples\n",
    "# ======================================================================\n",
    "\n",
    "# === Per-quarter samples ===\n",
    "quarterly_samples = sq.sample(nvidia_sample, n=N_SAMPLES)\n",
    "quarterly_intervals = get_quarterly_intervals(quarterly_samples)\n",
    "\n",
    "# === Cumulative samples (per chip) ===\n",
    "cumulative_samples = sq.sample(lambda: cumulative_by_chip(nvidia_sample()), n=N_SAMPLES)\n",
    "cumulative_intervals = get_chip_intervals(cumulative_samples)\n",
    "\n",
    "# === Total Nvidia stock (all chips, all quarters) ===\n",
    "total_samples = sq.sample(lambda: total_chips(nvidia_sample()), n=N_SAMPLES)\n",
    "total_intervals = get_scalar_intervals(total_samples)\n",
    "\n",
    "# === Cumulative total over time (running total by quarter) ===\n",
    "cumulative_total_samples = sq.sample(lambda: cumulative_total_by_quarter(nvidia_sample()), n=N_SAMPLES)\n",
    "\n",
    "print(f\"Collected {N_SAMPLES} samples for quarterly, cumulative, and total estimates.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Display quarterly summary by chip type\n",
    "# ======================================================================\n",
    "\n",
    "print(\"=== QUARTERLY CHIP SALES BY TYPE ===\\n\")\n",
    "\n",
    "for chip in CHIP_TYPES:\n",
    "    # Check if this chip has any sales\n",
    "    has_sales = any(quarterly_intervals[q][chip]['p50'] > 0 for q in QUARTERS)\n",
    "    if not has_sales:\n",
    "        continue\n",
    "    \n",
    "    print(f\"--- {chip} ---\")\n",
    "    print(f\"{'Quarter':<10} {'Units (p50)':>12} {'Units (90% CI)':>24} {'H100e (p50)':>12} {'H100e (90% CI)':>24}\")\n",
    "    \n",
    "    for quarter in QUARTERS:\n",
    "        stats = quarterly_intervals[quarter][chip]\n",
    "        if stats['p50'] > 0:\n",
    "            h100e_factor = CHIP_SPECS[chip]['tops'] / H100_TOPS\n",
    "            u_p5, u_p50, u_p95 = int(stats['p5']), int(stats['p50']), int(stats['p95'])\n",
    "            h_p5, h_p50, h_p95 = int(stats['p5'] * h100e_factor), int(stats['p50'] * h100e_factor), int(stats['p95'] * h100e_factor)\n",
    "            print(f\"{quarter:<10} {u_p50:>12,} {f'({u_p5:,} - {u_p95:,})':>24} {h_p50:>12,} {f'({h_p5:,} - {h_p95:,})':>24}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "display_cumulative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Display cumulative summary\n",
    "# ======================================================================\n",
    "\n",
    "print(\"\\nCumulative NVIDIA Chip Sales (FY23-FY27)\")\n",
    "print(f\"{'Version':<12} {'p5':>12} {'p50':>12} {'p95':>12}\")\n",
    "print(\"-\" * 51)\n",
    "\n",
    "for chip in CHIP_TYPES:\n",
    "    stats = cumulative_intervals[chip]\n",
    "    if stats['p50'] > 0:\n",
    "        print(f\"{chip:<12} {int(stats['p5']):>12,} {int(stats['p50']):>12,} {int(stats['p95']):>12,}\")\n",
    "\n",
    "print(\"-\" * 51)\n",
    "print(f\"{'TOTAL':<12} {int(total_intervals['p5']):>12,} {int(total_intervals['p50']):>12,} {int(total_intervals['p95']):>12,}\")\n",
    "\n",
    "# H100 equivalents\n",
    "print(\"\\n\\nH100 Equivalents (8-bit TOPS basis)\")\n",
    "print(f\"{'Version':<12} {'p5':>12} {'p50':>12} {'p95':>12}\")\n",
    "print(\"-\" * 51)\n",
    "\n",
    "h100e_total = {'p5': 0, 'p50': 0, 'p95': 0}\n",
    "for chip in CHIP_TYPES:\n",
    "    stats = cumulative_intervals[chip]\n",
    "    if stats['p50'] > 0:\n",
    "        h100e_factor = CHIP_SPECS[chip]['tops'] / H100_TOPS\n",
    "        h_p5, h_p50, h_p95 = int(stats['p5'] * h100e_factor), int(stats['p50'] * h100e_factor), int(stats['p95'] * h100e_factor)\n",
    "        print(f\"{chip:<12} {h_p5:>12,} {h_p50:>12,} {h_p95:>12,}\")\n",
    "        h100e_total['p5'] += h_p5\n",
    "        h100e_total['p50'] += h_p50\n",
    "        h100e_total['p95'] += h_p95\n",
    "\n",
    "print(\"-\" * 51)\n",
    "print(f\"{'TOTAL':<12} {h100e_total['p5']:>12,} {h100e_total['p50']:>12,} {h100e_total['p95']:>12,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cumulative_chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Cumulative NVIDIA Sales by Chip Type (H100-equivalent units)\n",
    "# ======================================================================\n",
    "\n",
    "# Get median values for each chip type, converted to H100-equivalents\n",
    "chip_medians = {}\n",
    "for chip in CHIP_TYPES:\n",
    "    quarterly_medians = [quarterly_intervals[q][chip]['p50'] for q in QUARTERS]\n",
    "    h100e_ratio = CHIP_SPECS[chip]['tops'] / H100_TOPS\n",
    "    chip_medians[chip] = np.array(quarterly_medians) * h100e_ratio\n",
    "\n",
    "# Calculate cumulative sums\n",
    "chip_cumulative = {chip: np.cumsum(chip_medians[chip]) for chip in CHIP_TYPES}\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "x = np.arange(len(QUARTERS))\n",
    "width = 0.6\n",
    "\n",
    "bottom = np.zeros(len(QUARTERS))\n",
    "for chip in CHIP_TYPES:\n",
    "    ax.bar(x, chip_cumulative[chip], width, label=chip, bottom=bottom, color=CHIP_COLORS[chip])\n",
    "    bottom += chip_cumulative[chip]\n",
    "\n",
    "ax.set_ylabel('Cumulative H100-Equivalent Units', fontsize=12)\n",
    "ax.set_xlabel('Quarter', fontsize=12)\n",
    "ax.set_title('Cumulative NVIDIA Sales by Chip Type\\n(H100-Equivalent Units)', fontsize=14, pad=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(QUARTERS, rotation=45, ha='right')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, p: f'{y/1e6:.1f}M'))\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "ax.legend(fontsize=10, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert_to_legacy_format",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================\n",
    "# Convert to legacy format for export functions\n",
    "# ======================================================================\n",
    "\n",
    "# The export functions expect {quarter: {chip: [list of samples]}}\n",
    "# We need to reorganize our quarterly_samples to match\n",
    "\n",
    "sim_results = {q: {c: [] for c in CHIP_TYPES} for q in QUARTERS}\n",
    "for sample in quarterly_samples:\n",
    "    for q in QUARTERS:\n",
    "        for c in CHIP_TYPES:\n",
    "            sim_results[q][c].append(sample[q][c])\n",
    "\n",
    "# Convert lists to arrays for compatibility\n",
    "for q in QUARTERS:\n",
    "    for c in CHIP_TYPES:\n",
    "        sim_results[q][c] = np.array(sim_results[q][c])\n",
    "\n",
    "print(\"Converted samples to legacy format for export.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_fiscal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# EXPORT NON-INTERPOLATED FISCAL QUARTER RESULTS\n",
    "# ==============================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current timestamp for notes\n",
    "timestamp = datetime.now().strftime(\"%m-%d-%Y %H:%M\")\n",
    "generated_note = f\"Estimates generated on: {timestamp}\"\n",
    "\n",
    "# Create rows for output (fiscal quarters, non-interpolated)\n",
    "rows = []\n",
    "\n",
    "for quarter in QUARTERS:\n",
    "    start_date = revenue_df.loc[quarter, 'Start Date']\n",
    "    end_date = revenue_df.loc[quarter, 'End Date']\n",
    "    \n",
    "    for chip_type in CHIP_SPECS:\n",
    "        arr = np.array(sim_results[quarter][chip_type])\n",
    "        if arr.sum() > 0:\n",
    "            # Calculate percentiles for units\n",
    "            u_p5, u_p50, u_p95 = [int(np.percentile(arr, p)) for p in [5, 50, 95]]\n",
    "            \n",
    "            # Calculate H100 equivalents\n",
    "            h100e_factor = CHIP_SPECS[chip_type]['tops'] / H100_TOPS\n",
    "            h_p5, h_p50, h_p95 = [int(p * h100e_factor) for p in [u_p5, u_p50, u_p95]]\n",
    "            \n",
    "            # Use display name (H100/H200 -> H100 for display)\n",
    "            display_name = 'H100' if chip_type == 'H100/H200' else chip_type\n",
    "            \n",
    "            rows.append({\n",
    "                'Name': f\"{quarter} - {display_name}\",\n",
    "                'Chip manufacturer': 'Nvidia',\n",
    "                'Start date': start_date,\n",
    "                'End date': end_date,\n",
    "                'Compute estimate in H100e (median)': h_p50,\n",
    "                'H100e (5th percentile)': h_p5,\n",
    "                'H100e (95th percentile)': h_p95,\n",
    "                'Number of Units': u_p50,\n",
    "                'Number of Units (5th percentile)': u_p5,\n",
    "                'Number of Units (95th percentile)': u_p95,\n",
    "                'Source / Link': '',\n",
    "                'Notes': generated_note,\n",
    "                'Chip type': display_name,\n",
    "                'Last Modified By': '',\n",
    "                'Last Modified': '',\n",
    "            })\n",
    "\n",
    "# Create output dataframe\n",
    "nvidia_chip_timelines = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'nvidia_chip_timelines.csv'\n",
    "nvidia_chip_timelines.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Exported to {output_path}\")\n",
    "print(nvidia_chip_timelines[['Name', 'Chip manufacturer', 'Start date', 'End date', \n",
    "                              'Compute estimate in H100e (median)', 'H100e (5th percentile)', \n",
    "                              'H100e (95th percentile)', 'Number of Units', 'Chip type']].to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpolate_calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# INTERPOLATE TO CALENDAR QUARTERS\n",
    "# ==============================================\n",
    "\n",
    "from chip_estimates_utils import (\n",
    "    interpolate_to_calendar_quarters,\n",
    "    summarize_calendar_quarters,\n",
    ")\n",
    "\n",
    "# Use Start Date and End Date directly from revenue_df\n",
    "quarter_dates = {q: (revenue_df.loc[q, 'Start Date'], revenue_df.loc[q, 'End Date']) for q in QUARTERS}\n",
    "\n",
    "print(\"NVIDIA fiscal quarter to calendar date mapping:\")\n",
    "for q, (start, end) in list(quarter_dates.items())[:5]:\n",
    "    print(f\"  {q}: {start} to {end}\")\n",
    "print(\"  ...\")\n",
    "\n",
    "# Interpolate to calendar quarters\n",
    "calendar_results = interpolate_to_calendar_quarters(sim_results, quarter_dates, verbose=False)\n",
    "\n",
    "# Display summary\n",
    "calendar_summary = summarize_calendar_quarters(calendar_results)\n",
    "print(\"\\nNVIDIA Chip Volumes by Calendar Quarter (median with 90% CI)\")\n",
    "print(calendar_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export_calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# EXPORT INTERPOLATED CALENDAR QUARTER RESULTS\n",
    "# ==============================================\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Get current timestamp for notes\n",
    "timestamp = datetime.now().strftime(\"%m-%d-%Y %H:%M\")\n",
    "generated_note = f\"Estimates generated on: {timestamp}\"\n",
    "\n",
    "# Get first and last dates from Nvidia fiscal quarter data\n",
    "nvidia_first_start = revenue_df['Start Date'].iloc[0]\n",
    "nvidia_last_end = revenue_df['End Date'].iloc[-1]\n",
    "\n",
    "# Parse date strings to datetime for comparison\n",
    "def parse_date(date_str):\n",
    "    \"\"\"Parse date string to datetime.\"\"\"\n",
    "    return pd.to_datetime(date_str)\n",
    "\n",
    "nvidia_first_start_dt = parse_date(nvidia_first_start)\n",
    "nvidia_last_end_dt = parse_date(nvidia_last_end)\n",
    "\n",
    "# Calendar quarter to date range mapping\n",
    "def get_calendar_quarter_dates(cal_q):\n",
    "    \"\"\"Return (start_date, end_date) strings for a calendar quarter like 'Q1 2024'.\"\"\"\n",
    "    parts = cal_q.split()\n",
    "    q_num = int(parts[0][1])\n",
    "    year = int(parts[1])\n",
    "    if q_num == 1:\n",
    "        return f\"1/1/{year}\", f\"3/31/{year}\"\n",
    "    elif q_num == 2:\n",
    "        return f\"4/1/{year}\", f\"6/30/{year}\"\n",
    "    elif q_num == 3:\n",
    "        return f\"7/1/{year}\", f\"9/30/{year}\"\n",
    "    else:\n",
    "        return f\"10/1/{year}\", f\"12/31/{year}\"\n",
    "\n",
    "def format_date_for_note(dt):\n",
    "    \"\"\"Format datetime as M/D/YYYY for notes.\"\"\"\n",
    "    return dt.strftime('%-m/%-d/%Y') if hasattr(dt, 'strftime') else str(dt)\n",
    "\n",
    "def get_incomplete_note(cal_q_start, cal_q_end):\n",
    "    \"\"\"Return note if calendar quarter extends beyond Nvidia fiscal data coverage.\"\"\"\n",
    "    cal_start_dt = pd.to_datetime(cal_q_start, format='%m/%d/%Y')\n",
    "    cal_end_dt = pd.to_datetime(cal_q_end, format='%m/%d/%Y')\n",
    "\n",
    "    starts_before = cal_start_dt < nvidia_first_start_dt\n",
    "    ends_after = cal_end_dt > nvidia_last_end_dt\n",
    "\n",
    "    first_start_str = format_date_for_note(nvidia_first_start_dt)\n",
    "    last_end_str = format_date_for_note(nvidia_last_end_dt)\n",
    "\n",
    "    if starts_before and ends_after:\n",
    "        return f\"Estimate is incomplete because it is based on Nvidia fiscal quarters beginning {first_start_str} and ending {last_end_str}\"\n",
    "    elif starts_before:\n",
    "        return f\"Estimate is incomplete because it is based on Nvidia fiscal quarters beginning {first_start_str}\"\n",
    "    elif ends_after:\n",
    "        return f\"Estimate is incomplete because it is based on Nvidia fiscal quarters ending {last_end_str}\"\n",
    "    return None\n",
    "\n",
    "# Create rows for output\n",
    "rows = []\n",
    "\n",
    "for quarter in calendar_results:\n",
    "    start_date, end_date = get_calendar_quarter_dates(quarter)\n",
    "    incomplete_note = get_incomplete_note(start_date, end_date)\n",
    "\n",
    "    for chip_type in CHIP_SPECS:\n",
    "        stats = calendar_results[quarter][chip_type]\n",
    "        if stats['p50'] > 0:\n",
    "            # Calculate H100 equivalents\n",
    "            h100e_factor = CHIP_SPECS[chip_type]['tops'] / H100_TOPS\n",
    "\n",
    "            # Build notes field\n",
    "            notes = generated_note\n",
    "            if incomplete_note:\n",
    "                notes = f\"{incomplete_note}. {notes}\"\n",
    "\n",
    "            rows.append({\n",
    "                'Name': f\"{quarter} - {chip_type}\",\n",
    "                'Chip manufacturer': 'Nvidia',\n",
    "                'Start date': start_date,\n",
    "                'End date': end_date,\n",
    "                'Compute estimate in H100e (median)': int(stats['p50'] * h100e_factor),\n",
    "                'H100e (5th percentile)': int(stats['p5'] * h100e_factor),\n",
    "                'H100e (95th percentile)': int(stats['p95'] * h100e_factor),\n",
    "                'Number of Units': int(stats['p50']),\n",
    "                'Number of Units (5th percentile)': int(stats['p5']),\n",
    "                'Number of Units (95th percentile)': int(stats['p95']),\n",
    "                'Source / Link': '',\n",
    "                'Notes': notes,\n",
    "                'Chip type': chip_type,\n",
    "                'Last Modified By': '',\n",
    "                'Last Modified': '',\n",
    "            })\n",
    "\n",
    "# Create output dataframe\n",
    "nvidia_timelines_interpolated = pd.DataFrame(rows)\n",
    "\n",
    "# Save to CSV\n",
    "output_path = 'nvidia_timelines_interpolated.csv'\n",
    "nvidia_timelines_interpolated.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Exported to {output_path}\")\n",
    "print(f\"Nvidia fiscal data coverage: {format_date_for_note(nvidia_first_start_dt)} to {format_date_for_note(nvidia_last_end_dt)}\")\n",
    "print(nvidia_timelines_interpolated[['Name', 'Chip manufacturer', 'Start date', 'End date', \n",
    "                                      'Compute estimate in H100e (median)', 'H100e (5th percentile)', \n",
    "                                      'H100e (95th percentile)', 'Number of Units', 'Chip type']].head(20).to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
