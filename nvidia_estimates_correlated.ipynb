{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import squigglepy as sq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from squigglepy.numbers import K, M, B\n",
    "\n",
    "sq.set_seed(42)\n",
    "np.random.seed(42)\n",
    "N_SAMPLES = 5000\n",
    "\n",
    "from chip_estimates_utils import (\n",
    "    estimate_chip_sales,\n",
    "    estimate_cumulative_chip_sales,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA chip types\n",
    "CHIP_TYPES = ['A100', 'A800', 'H100/H200', 'H800', 'H20', 'B200', 'B300']\n",
    "\n",
    "# Hardware share of compute revenue (vs cloud/software)\n",
    "HARDWARE_SHARE = sq.to(0.96, 0.99, credibility=80)\n",
    "\n",
    "# Revenue estimation bias (systematic over/under-estimation)\n",
    "# REVENUE_BIAS = sq.to(0.90, 1.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load_data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 15 quarters of data\n",
      "         Compute revenue\n",
      "Quarter                 \n",
      "FY23Q1              2.81\n",
      "FY23Q2              2.86\n",
      "FY23Q3              2.87\n",
      "FY23Q4              2.72\n",
      "FY24Q1              3.35\n",
      "\n",
      "      A100 low  A100 high  Notes  H100 low  H100 high  Geomean  Notes.1  \\\n",
      "Year                                                                      \n",
      "2022     10000      15000    NaN     27000      35000  $30,741      NaN   \n",
      "2023     10000      15000    NaN     27000      35000  $30,741      NaN   \n",
      "2024     10000      15000    NaN     25000      32000  $28,284      NaN   \n",
      "2025     10000      15000    NaN     22000      30000  $25,690      NaN   \n",
      "\n",
      "      B200 low  B200 high Geomean.1  ...  Geomean.2  Notes.3  H20 low  \\\n",
      "Year                                 ...                                \n",
      "2022       NaN        NaN       NaN  ...        NaN      NaN      NaN   \n",
      "2023       NaN        NaN       NaN  ...        NaN      NaN      NaN   \n",
      "2024   33000.0    42000.0   $37,229  ...        NaN      NaN  10000.0   \n",
      "2025   33000.0    42000.0   $37,229  ...    $43,151      NaN  10000.0   \n",
      "\n",
      "     H20 high  Geomean.3  A800 low  A800 high Notes.4  H800 low  H800 high  \n",
      "Year                                                                        \n",
      "2022      NaN        NaN   10000.0    15000.0     NaN       NaN        NaN  \n",
      "2023      NaN        NaN   10000.0    15000.0     NaN   25000.0    35000.0  \n",
      "2024  15000.0    $12,247       NaN        NaN     NaN       NaN        NaN  \n",
      "2025  13000.0    $11,402       NaN        NaN     NaN       NaN        NaN  \n",
      "\n",
      "[4 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load revenue and price data from Google Sheets\n",
    "revenue_df = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/1Yhu87Rw--9tviAuBwg_luL3OFAFkdHdVfli6tN215Xk/export?format=csv&gid=0\"\n",
    ").set_index('Quarter')\n",
    "\n",
    "prices_df = pd.read_csv(\n",
    "    \"https://docs.google.com/spreadsheets/d/1Yhu87Rw--9tviAuBwg_luL3OFAFkdHdVfli6tN215Xk/export?format=csv&gid=1819303346\"\n",
    ").set_index('Year')\n",
    "\n",
    "QUARTERS = revenue_df.index.tolist()\n",
    "\n",
    "print(f\"Loaded {len(QUARTERS)} quarters of data\")\n",
    "print(revenue_df[['Compute revenue']].head())\n",
    "print()\n",
    "print(prices_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "price_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base prices (first year available for each chip):\n",
      "  A100 (2022): $10,000 - $15,000\n",
      "  A800 (2022): $10,000 - $15,000\n",
      "  H100/H200 (2022): $27,000 - $35,000\n",
      "  H800 (2023): $25,000 - $35,000\n",
      "  H20 (2024): $10,000 - $15,000\n",
      "  B200 (2024): $33,000 - $42,000\n",
      "  B300 (2025): $38,000 - $49,000\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# BASE PRICE AND DEFLATION SETUP\n",
    "# ==============================================\n",
    "\n",
    "# Map chip types to their column names in the prices CSV\n",
    "PRICE_COLUMN_MAP = {'H100/H200': 'H100'}\n",
    "\n",
    "# Fallback prices if not found in CSV\n",
    "FALLBACK_PRICES = {\n",
    "    'A100': (10*K, 15*K), 'A800': (10*K, 15*K), 'H100/H200': (20*K, 30*K),\n",
    "    'H800': (20*K, 30*K), 'H20': (10*K, 15*K), 'B200': (33*K, 42*K), 'B300': (33*K, 42*K)\n",
    "}\n",
    "\n",
    "# Build base price distributions (from first available year for each chip)\n",
    "def get_price_dist_for_year(chip, year):\n",
    "    \"\"\"Get price distribution for a chip in a given year.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col, high_col = f'{csv_chip_name} low', f'{csv_chip_name} high'\n",
    "    \n",
    "    if low_col in prices_df.columns and high_col in prices_df.columns:\n",
    "        if year in prices_df.index:\n",
    "            low = prices_df.loc[year, low_col]\n",
    "            high = prices_df.loc[year, high_col]\n",
    "            if pd.notna(low) and pd.notna(high):\n",
    "                return sq.to(low, high, credibility=80)\n",
    "    \n",
    "    return sq.to(*FALLBACK_PRICES.get(chip, (20*K, 30*K)), credibility=80)\n",
    "\n",
    "# Find first year each chip has price data\n",
    "def find_first_year_with_price(chip):\n",
    "    \"\"\"Find the first year with price data for a chip.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col = f'{csv_chip_name} low'\n",
    "    \n",
    "    if low_col in prices_df.columns:\n",
    "        for year in sorted(prices_df.index):\n",
    "            if pd.notna(prices_df.loc[year, low_col]):\n",
    "                return year\n",
    "    return min(prices_df.index)  # fallback to first year\n",
    "\n",
    "# Build base prices dict\n",
    "BASE_YEAR = {chip: find_first_year_with_price(chip) for chip in CHIP_TYPES}\n",
    "BASE_PRICES = {chip: get_price_dist_for_year(chip, BASE_YEAR[chip]) for chip in CHIP_TYPES}\n",
    "\n",
    "print(\"Base prices (first year available for each chip):\")\n",
    "for chip in CHIP_TYPES:\n",
    "    dist = BASE_PRICES[chip]\n",
    "    print(f\"  {chip} ({BASE_YEAR[chip]}): ${dist.x:,.0f} - ${dist.y:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deflation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deflation factors by year (ratio to base year):\n",
      "  A100: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 1.0}\n",
      "  A800: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 1.0}\n",
      "  H100/H200: {2022: 1.0, 2023: 1.0, 2024: 0.92, 2025: 0.836}\n",
      "  H800: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 1.0}\n",
      "  H20: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 0.931}\n",
      "  B200: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 1.0}\n",
      "  B300: {2022: 1.0, 2023: 1.0, 2024: 1.0, 2025: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# DEFLATION FACTORS\n",
    "# ==============================================\n",
    "\n",
    "def get_price_bounds(chip, year):\n",
    "    \"\"\"Get (low, high) price bounds for a chip in a given year, or None if unavailable.\"\"\"\n",
    "    csv_chip_name = PRICE_COLUMN_MAP.get(chip, chip)\n",
    "    low_col, high_col = f'{csv_chip_name} low', f'{csv_chip_name} high'\n",
    "\n",
    "    if low_col in prices_df.columns and high_col in prices_df.columns:\n",
    "        if year in prices_df.index:\n",
    "            low = prices_df.loc[year, low_col]\n",
    "            high = prices_df.loc[year, high_col]\n",
    "            if pd.notna(low) and pd.notna(high):\n",
    "                return (low, high)\n",
    "    return None\n",
    "\n",
    "def get_price_year_for_quarter(quarter):\n",
    "    \"\"\"Get the calendar year to use for pricing a quarter.\"\"\"\n",
    "    start_date = revenue_df.loc[quarter, 'Start Date']\n",
    "    return pd.to_datetime(start_date).year\n",
    "\n",
    "def get_deflation_factor(quarter, chip):\n",
    "    \"\"\"Get deflation factor for a chip in a quarter (ratio of current price to base price).\"\"\"\n",
    "    price_year = get_price_year_for_quarter(quarter)\n",
    "    base_year = BASE_YEAR[chip]\n",
    "\n",
    "    if price_year <= base_year:\n",
    "        return 1.0\n",
    "\n",
    "    base_bounds = get_price_bounds(chip, base_year)\n",
    "    current_bounds = get_price_bounds(chip, price_year)\n",
    "\n",
    "    if base_bounds and current_bounds:\n",
    "        # For lognormal sq.to(low, high), geometric mean = sqrt(low * high)\n",
    "        return np.sqrt((current_bounds[0] * current_bounds[1]) / (base_bounds[0] * base_bounds[1]))\n",
    "    return 1.0\n",
    "\n",
    "# Print deflation factors for reference\n",
    "print(\"Deflation factors by year (ratio to base year):\")\n",
    "years = sorted(prices_df.index)\n",
    "for chip in CHIP_TYPES:\n",
    "    factors = {}\n",
    "    for year in years:\n",
    "        # Find a quarter in this year to test\n",
    "        for q in QUARTERS:\n",
    "            if get_price_year_for_quarter(q) == year:\n",
    "                factors[year] = round(get_deflation_factor(q, chip), 3)\n",
    "                break\n",
    "    if factors:\n",
    "        print(f\"  {chip}: {factors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sampling_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# SAMPLING FUNCTIONS\n",
    "# ==============================================\n",
    "\n",
    "def sample_revenue(quarter):\n",
    "    \"\"\"Sample revenue for a quarter.\"\"\"\n",
    "    base_revenue = revenue_df.loc[quarter, 'Compute revenue'] * B\n",
    "    return base_revenue * (HARDWARE_SHARE @ 1)\n",
    "\n",
    "def sample_shares(quarter):\n",
    "    \"\"\"Sample chip shares for a quarter.\"\"\"\n",
    "    return {chip: revenue_df.loc[quarter, f'{chip} share'] for chip in CHIP_TYPES}\n",
    "\n",
    "def sample_base_price(chip):\n",
    "    \"\"\"Sample base price for a chip (from its first available year).\"\"\"\n",
    "    return BASE_PRICES[chip] @ 1\n",
    "\n",
    "# Cache price distributions by (chip, year) to avoid recreating them on every sample\n",
    "PRICE_DIST_CACHE = {}\n",
    "\n",
    "def sample_price(quarter, chip):\n",
    "    \"\"\"Sample price for a chip in a quarter (for uncorrelated model).\"\"\"\n",
    "    year = get_price_year_for_quarter(quarter)\n",
    "    cache_key = (chip, year)\n",
    "    if cache_key not in PRICE_DIST_CACHE:\n",
    "        PRICE_DIST_CACHE[cache_key] = get_price_dist_for_year(chip, year)\n",
    "    return PRICE_DIST_CACHE[cache_key] @ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785c4634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Run Monte Carlo simulation to estimate cumulative chip volumes with correlated parameters.\n",
      "\n",
      "    Similar to estimate_chip_sales, but presamples certain parameters to correlate them\n",
      "    across quarters. Use this when estimating cumulative totals where you want price\n",
      "    uncertainty (and optionally revenue bias) to compound rather than average out.\n",
      "\n",
      "    Args:\n",
      "        quarters: list of quarter identifiers (e.g., ['Q1_2023', 'Q2_2023', ...])\n",
      "        chip_types: list of chip types (e.g., ['alpha', 'beta', 'gamma', ...])\n",
      "        sample_revenue: fn(quarter) -> float, samples total chip revenue in dollars for a quarter\n",
      "        sample_shares: fn(quarter) -> dict, samples {chip: share} for a quarter (should sum to 1)\n",
      "        sample_base_price: fn(chip) -> float, samples the BASE price for a chip type\n",
      "            (i.e., the price when the chip was first introduced). Called once per chip;\n",
      "            subsequent quarters use this base price scaled by get_deflation_factor.\n",
      "        get_deflation_factor: fn(quarter, chip) -> float, returns price multiplier for a\n",
      "            quarter relative to the base price. Should return 1.0 for the chip's first\n",
      "            quarter and <1.0 for later quarters as prices decline. If None, no deflation.\n",
      "        revenue_bias_dist: squigglepy distribution for systematic revenue estimation error.\n",
      "            Sampled once and applied as a multiplier to all quarters. If None, no bias.\n",
      "        n_samples: number of Monte Carlo samples\n",
      "\n",
      "    Returns:\n",
      "        dict of {chip: np.array of cumulative chip counts across all quarters}\n",
      "        Each array has n_samples elements representing the distribution of total chips.\n",
      "\n",
      "    Note on correlations:\n",
      "        - Prices are sampled once per chip type and reused (with deflation) across all quarters.\n",
      "          This means if we sample a \"high price world\", that persists for the entire simulation.\n",
      "        - Revenue bias (if provided) is sampled once and applied to all quarters.\n",
      "        - Revenue and production mix shares are sampled independently each quarter.\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print(estimate_cumulative_chip_sales.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation complete.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# RUN CORRELATED SIMULATION\n",
    "# ==============================================\n",
    "\n",
    "cumulative_results = estimate_cumulative_chip_sales(\n",
    "    quarters=QUARTERS,\n",
    "    chip_types=CHIP_TYPES,\n",
    "    sample_revenue=sample_revenue,\n",
    "    sample_shares=sample_shares,\n",
    "    sample_base_price=sample_base_price,\n",
    "    get_deflation_factor=get_deflation_factor,\n",
    "    # revenue_bias_dist=REVENUE_BIAS,\n",
    "    n_samples=N_SAMPLES\n",
    ")\n",
    "\n",
    "print(\"Simulation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cumulative Nvidia Chip Sales (Correlated Model)\n",
      "Version                p5          p50          p95\n",
      "---------------------------------------------------\n",
      "A100              693,455      896,896    1,171,495\n",
      "H100/H200       3,623,153    4,318,831    5,078,247\n",
      "H20             1,146,356    1,490,083    1,941,137\n",
      "B200            1,364,481    1,598,031    1,871,535\n",
      "B300              793,466      938,315    1,101,202\n",
      "---------------------------------------------------\n",
      "TOTAL           8,423,530    9,296,077   10,181,843\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# CUMULATIVE SUMMARY\n",
    "# ==============================================\n",
    "\n",
    "def print_cumulative_summary(cumulative_results, chip_types, title=\"Cumulative Production\"):\n",
    "    \"\"\"Print formatted summary of cumulative chip counts with percentiles.\"\"\"\n",
    "    print(f\"\\n{title}\")\n",
    "    print(f\"{'Version':<12} {'p5':>12} {'p50':>12} {'p95':>12}\")\n",
    "    print(\"-\" * 51)\n",
    "\n",
    "    grand_total = None\n",
    "    for chip in chip_types:\n",
    "        arr = cumulative_results[chip]\n",
    "        if arr.sum() > 0:\n",
    "            if grand_total is None:\n",
    "                grand_total = np.zeros_like(arr)\n",
    "            grand_total += arr\n",
    "            print(f\"{chip:<12} {int(np.percentile(arr, 5)):>12,} {int(np.percentile(arr, 50)):>12,} {int(np.percentile(arr, 95)):>12,}\")\n",
    "\n",
    "    if grand_total is not None:\n",
    "        print(\"-\" * 51)\n",
    "        print(f\"{'TOTAL':<12} {int(np.percentile(grand_total, 5)):>12,} {int(np.percentile(grand_total, 50)):>12,} {int(np.percentile(grand_total, 95)):>12,}\")\n",
    "\n",
    "print_cumulative_summary(cumulative_results, CHIP_TYPES, \"Cumulative Nvidia Chip Sales (Correlated Model)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================\n",
    "# UNCORRELATED MODEL COMPARISON\n",
    "# ==============================================\n",
    "\n",
    "# Run uncorrelated simulation (price sampled independently each quarter)\n",
    "uncorrelated = estimate_chip_sales(\n",
    "    quarters=QUARTERS,\n",
    "    versions=CHIP_TYPES,\n",
    "    sample_revenue=sample_revenue,\n",
    "    sample_shares=sample_shares,\n",
    "    sample_price=sample_price,\n",
    "    n_samples=2000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360ee202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cumulative NVIDIA Chip Sales (FY23-FY27)\n",
      "Version                p5          p50          p95\n",
      "---------------------------------------------------\n",
      "A100              806,581      906,310    1,018,946\n",
      "A800              107,117      122,059      140,150\n",
      "H100/H200       4,083,051    4,328,671    4,579,424\n",
      "H800              102,134      116,889      135,469\n",
      "H20             1,360,134    1,508,845    1,669,918\n",
      "B200            1,479,562    1,600,851    1,739,541\n",
      "B300              835,487      939,491    1,063,568\n",
      "---------------------------------------------------\n",
      "TOTAL           9,182,745    9,535,439    9,900,509\n"
     ]
    }
   ],
   "source": [
    "cumulative_uncorrelated = {chip: np.zeros(2000) for chip in CHIP_TYPES}\n",
    "for quarter in uncorrelated:\n",
    "    for chip in CHIP_TYPES:\n",
    "        cumulative_uncorrelated[chip] += np.array(uncorrelated[quarter][chip])\n",
    "\n",
    "print_cumulative_summary(cumulative_uncorrelated, CHIP_TYPES, \"Cumulative Nvidia Chip Sales (uncorrelated model)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Plotly)",
   "language": "python",
   "name": "plotly_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
